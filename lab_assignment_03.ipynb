{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tk03145/tharun_INFO5502_SPRING2022/blob/main/lab_assignment_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CExH9YCPXEX1"
      },
      "source": [
        "## The third Lab-assignment (02/10/2022, 50 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYIpQvf5XEX3"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dfyQVPsXEX4"
      },
      "source": [
        "Question 1 (10 points). Fomulate your domain problem: Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li1ZLqv5XEX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "093beb07-3d55-4149-e142-64cd967225ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nPlease write you answer here:\\n\\nI'm looking for nonfiction books to read after harry poter series on their ratings.\\nTo extract data, I utilized the Goodreads website.\\nGood reads is a collection of books from various genres, as well as their name of the book,score and user ratings these are designed as coloumns.\\nI initially chose the goodreads website and extracted the information using a web scraping approach.\\nTo begin, I imported the requests library to read data from URLs and used the for loop to cycle through all of the pages.\\nThen, to extract data from html files, I utilized the beautifulsoup library.\\nI developed a table to define a table (based on HTML element)for the soup to read\\nthen stored and inserted data such as the author's name, the title of the book, and ratings based on HTML components.\\nUltimately\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "I'm looking for nonfiction books to read after harry poter series on their ratings.\n",
        "To extract data, I utilized the Goodreads website.\n",
        "Good reads is a collection of books from various genres, as well as their name of the book,score and user ratings these are designed as coloumns.\n",
        "I initially chose the goodreads website and extracted the information using a web scraping approach.\n",
        "To begin, I imported the requests library to read data from URLs and used the for loop to cycle through all of the pages.\n",
        "Then, to extract data from html files, I utilized the beautifulsoup library.\n",
        "I developed a table to define a table (based on HTML element)for the soup to read\n",
        "then stored and inserted data such as the author's name, the title of the book, and ratings based on HTML components.\n",
        "Ultimately\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK01bSSIXEX8"
      },
      "source": [
        "Question 2 (10 points). Collect your data to answer the research problem: Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y81-GL3eXEX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffd2c17-7c4b-4e5c-8a89-ce0b0182f5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1 completed in 2.2800755500793457 seconds\n",
            "Page 2 completed in 2.3007678985595703 seconds\n",
            "Page 3 completed in 2.969135046005249 seconds\n",
            "Page 4 completed in 2.3945705890655518 seconds\n",
            "Page 5 completed in 2.5142159461975098 seconds\n",
            "Page 6 completed in 2.776663303375244 seconds\n",
            "Page 7 completed in 2.3406448364257812 seconds\n",
            "Page 8 completed in 2.3515331745147705 seconds\n",
            "Page 9 completed in 2.599757194519043 seconds\n",
            "Page 10 completed in 2.259815216064453 seconds\n",
            "Page 11 completed in 2.6780800819396973 seconds\n",
            "Page 12 completed in 2.7969276905059814 seconds\n",
            "Page 13 completed in 2.8715832233428955 seconds\n",
            "Page 14 completed in 2.68082594871521 seconds\n",
            "Page 15 completed in 2.5309557914733887 seconds\n",
            "Page 16 completed in 2.7186975479125977 seconds\n",
            "Page 17 completed in 2.5416438579559326 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import re\n",
        "import time\n",
        "\n",
        "bookname = []\n",
        "author = []\n",
        "Score = []\n",
        "pagenum= []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(1,18): # go throught the 23 pages\n",
        "    start_time = time.time()\n",
        "    URL = 'https://www.goodreads.com/list/show/559.What_To_Read_After_Harry_Potter?page={}'.format(i)\n",
        "    page = requests.get(URL)\n",
        "    pagecontent = page.text\n",
        "    soup = BeautifulSoup(pagecontent)\n",
        "    right_table=soup.find('table', class_='tableList js-dataTooltip')\n",
        "\n",
        "    for row in right_table.findAll(\"tr\"):\n",
        "        name = row.find('span', attrs = {'itemprop':'name'})\n",
        "        #author = row.find('a', attrs = {'class':'naame'})\n",
        "        score = row.find('span', attrs = {'class':'smallText uitext'})\n",
        "        bookname.append(name.text)\n",
        "        #author.append(author.text)\n",
        "        Score.append(score.text)\n",
        "        \n",
        "            \n",
        "        pagenum.append(i)\n",
        "\n",
        "    print('Page {} completed in {} seconds'.format(i, time.time()-start_time))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fIXT98A8YAc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_dfr = pd.DataFrame({'BookName':bookname, 'Score': Score, 'PageNo': pagenum})"
      ],
      "metadata": {
        "id": "0y_uwuZs0kBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_dfr.to_csv(r'Users\\saith\\Downloads\\.csv')\n",
        "\n",
        "books_dfr.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kZK6Lsbu0r7Z",
        "outputId": "f5a7845f-c311-4174-afec-44ec84ff53e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d53160c-239d-4a1e-bb14-4c444a5f2ded\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BookName</th>\n",
              "      <th>Score</th>\n",
              "      <th>PageNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Lightning Thief (Percy Jackson and the Oly...</td>\n",
              "      <td>\\nscore: 166,049,\\n              and\\n1,678 pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
              "      <td>\\nscore: 141,520,\\n              and\\n1,435 pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eragon (The Inheritance Cycle, #1)</td>\n",
              "      <td>\\nscore: 88,461,\\n              and\\n901 peopl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n",
              "      <td>\\nscore: 71,001,\\n              and\\n731 peopl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Artemis Fowl (Artemis Fowl, #1)</td>\n",
              "      <td>\\nscore: 64,980,\\n              and\\n665 peopl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d53160c-239d-4a1e-bb14-4c444a5f2ded')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d53160c-239d-4a1e-bb14-4c444a5f2ded button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d53160c-239d-4a1e-bb14-4c444a5f2ded');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            BookName  ... PageNo\n",
              "0  The Lightning Thief (Percy Jackson and the Oly...  ...      1\n",
              "1            The Hunger Games (The Hunger Games, #1)  ...      1\n",
              "2                 Eragon (The Inheritance Cycle, #1)  ...      1\n",
              "3  The Fellowship of the Ring (The Lord of the Ri...  ...      1\n",
              "4                    Artemis Fowl (Artemis Fowl, #1)  ...      1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJkasCdWXEYF"
      },
      "source": [
        "Question 3 (10 points). Understand the data quality: Search a second hand dataset (any dataset) from kaggle or other websites. Describe the data quality problem of the dataset and explain your strtegy to clean the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Uo4nabLXEYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8499a0dc-3168-4758-aeac-e12a2c0f873b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nPlease write you answer here:\\n\\n-> I considered a COVID 19 data sets from Kaggle.\\nDataset:\\n. \\n. There are 10 data columns in the dataset. there are many duplicate records in the data set\\n. \\n\\nSteps to Clean the data set:\\n. If there are any higher case characters, we transform them to lower case. \\nRemove all of the data's stopwords. \\nRemove any unneeded spaces and special characters from the data. \\nOn the data, do filtering and tokenizing. Examine the data for any discrepancies. \\nIf the data is unbalanced, we apply the SMOTE approach to correct it by doing over and under sampling. \\nThen we can create a classifier model to determine whether the data is spam or not.\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "'''\n",
        "\n",
        "Please write you answer here:\n",
        "\n",
        "-> I considered a COVID 19 data sets from Kaggle.\n",
        "Dataset:\n",
        ". \n",
        ". There are 10 data columns in the dataset. there are many duplicate records in the data set\n",
        ". \n",
        "\n",
        "Steps to Clean the data set:\n",
        ". If there are any higher case characters, we transform them to lower case. \n",
        "Remove all of the data's stopwords. \n",
        "Remove any unneeded spaces and special characters from the data. \n",
        "On the data, do filtering and tokenizing. Examine the data for any discrepancies. \n",
        "If the data is unbalanced, we apply the SMOTE approach to correct it by doing over and under sampling. \n",
        "Then we can create a classifier model to determine whether the data is spam or not.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnSx1j-eXEYG"
      },
      "source": [
        "Question 4 (20 points). Data cleaning: There are two datasets TwADR-L (from Twitter) and AskAPatient (Link: https://zenodo.org/record/55013#.YgU2NN-ZO4T) for medical concept\n",
        "normalization. However, the two datasets have serious data quality problems. Please read the introduction of the datasets and clean the two datasets by following the steps in the statement.\n",
        "\n",
        "In the original dataset, the TwADR-L had 48,057 training, 1,256 validation and 1,427 test examples. The test set (all\n",
        "test samples from 10 folds combined) consists of 765 unique phrases and 273 unique classes (medical concepts). The AskAPatient dataset contained 156,652 training, 7,926 validation, and 8,662 test examples. The entire test set (all test samples\n",
        "from 10 folds combined) consists of 3,749 unique phrases and 1,035 unique classes (medical concepts). The authors\n",
        "randomly split each dataset into ten equal folds, ran 10-fold cross validation and reported the accuracy averaged across the\n",
        "ten folds. \n",
        "\n",
        "We found that, in the original data set, many phrase-label pairs appeared multiple times within the same training data file\n",
        "and also across the training and test data sets in the same fold. In the AskAPatient data set, on average 35.82% of the test data overlapped with training data in the same fold. In the Twitter (TwADR-L) dataset, on average 8.62% of the test set had an overlap with the training data in the same fold. Having a large overlap between the training and the test data can potentially\n",
        "introduce bias in the model and contribute to high accuracy. It is not unlikely that the high model performance reported in the original paper may be triggered by the the large overlap between the training and test sets.\n",
        "\n",
        "Therefore to remove the bias, we further cleaned and recreated the training, validation, and test sets such that each\n",
        "phrase-label pair appears only once in the entire dataset (either in training, validation or test set).\n",
        "\n",
        "(1) First, we combined all examples in training, validation and test data from the original data set and then removed all\n",
        "duplicate phrase-label pairs (examples that have the same phrase and label pair and appear more than once in training/validation/test datasets). Table II shows the statistics of the new dataset (after removing duplicates). The Twitter data set had 3,157 unique phrase-label pairs and 2,220 unique labels (medical concepts) while 173 phrases had multiple labels (i.e., they were assigned to more than one label). Many concepts had only one example, and the concept that had the most number\n",
        "of examples had 36 phrases. On average, each concept had 1.42 examples. The AskAPatient data set had 4,496 unique phrase-label pairs, 1,036 unique labels while 26 phrases had multiple labels. Table III shows examples of phrases that had multiple labels. For example, ‘mad’ can be mapped to ‘anger’ or ‘rage’ and ‘sore’ can be mapped to ‘pain’ or ‘myalgia’.\n",
        "\n",
        "(2) Second, we remove all concepts that had less than five examples. The statistics of the final data are shown in Table IV.\n",
        "\n",
        "(3) Third, we divide all examples without multiple labels into random 10 folds such that each unique phrase-label pair\n",
        "appears once in one of the 10 test sets. We add the pairs with multiple labels into the training data. This final 10-folds\n",
        "dataset is used in all our experiments.\n",
        "\n",
        "(The original paper can be download on canvas)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "lab_assignment_03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}